{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning with PyTorch\n",
    "We're going to train a neural network to classify dogs and cats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init, helpers, utils, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load my_train_helper.py\n",
    "def get_trainable(model_params):\n",
    "    return (p for p in model_params if p.requires_grad)\n",
    "\n",
    "\n",
    "def get_frozen(model_params):\n",
    "    return (p for p in model_params if not p.requires_grad)\n",
    "\n",
    "\n",
    "def all_trainable(model_params):\n",
    "    return all(p.requires_grad for p in model_params)\n",
    "\n",
    "\n",
    "def all_frozen(model_params):\n",
    "    return all(not p.requires_grad for p in model_params)\n",
    "\n",
    "\n",
    "def freeze_all(model_params):\n",
    "    for param in model_params:\n",
    "        param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# The Data - DogsCatsDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "_image_size = 224\n",
    "_mean = [0.485, 0.456, 0.406]\n",
    "_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "train_trans = transforms.Compose([\n",
    "    transforms.Resize(256),  # some images are pretty small\n",
    "    transforms.RandomCrop(_image_size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(.3, .3, .3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(_mean, _std),\n",
    "])\n",
    "val_trans = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(_image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(_mean, _std),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The implementation of the dataset does not really."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load my_datasets.py\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "from torchvision.datasets.folder import ImageFolder, default_loader\n",
    "from torchvision.datasets.utils import download_url, check_integrity\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# PyTorch\n",
    "class DogsCatsDataset(ImageFolder):\n",
    "    \"\"\"\n",
    "    The 'Dogs and Cats' dataset from kaggle.\n",
    "\n",
    "    https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/\n",
    "\n",
    "    Args:\n",
    "        root: the location where to store the dataset\n",
    "        suffix: path to the train/valid/sample dataset. See folder structure.\n",
    "        transform (callable, optional): A function/transform that takes in\n",
    "            an PIL image and returns a transformed version.\n",
    "            E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that\n",
    "            takes in the target and transforms it.\n",
    "        loader: A function to load an image given its path.\n",
    "        download: if ``True``, download the data.\n",
    "\n",
    "\n",
    "    The folder structure of the dataset is as follows::\n",
    "\n",
    "        └── dogscats\n",
    "            ├── sample\n",
    "            │   ├── train\n",
    "            │   │   ├── cats\n",
    "            │   │   └── dogs\n",
    "            │   └── valid\n",
    "            │       ├── cats\n",
    "            │       └── dogs\n",
    "            ├── train\n",
    "            │   ├── cats\n",
    "            │   └── dogs\n",
    "            └── valid\n",
    "                ├── cats\n",
    "                └── dogs\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    url = \"http://files.fast.ai/data/dogscats.zip\"\n",
    "    filename = \"dogscats.zip\"\n",
    "    checksum = \"aef22ec7d472dd60e8ee79eecc19f131\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        suffix: str,\n",
    "        transform=None,\n",
    "        target_transform=None,\n",
    "        loader=default_loader,\n",
    "        download=False,\n",
    "    ):\n",
    "        self.root = os.path.expanduser(root)\n",
    "\n",
    "        if download:\n",
    "            self._download()\n",
    "            self._extract()\n",
    "\n",
    "        if not self._check_integrity():\n",
    "            raise RuntimeError(\n",
    "                \"Dataset not found or corrupted. \"\n",
    "                \"You can use download=True to download it\"\n",
    "            )\n",
    "\n",
    "        path = os.path.join(self.root, \"dogscats\", suffix)\n",
    "        print(f\"Loading data from {path}.\")\n",
    "        assert os.path.isdir(path), f\"'{suffix}' is not valid.\"\n",
    "\n",
    "        super().__init__(path, transform, target_transform, loader)\n",
    "\n",
    "    def _download(self):\n",
    "        if self._check_integrity():\n",
    "            print(\"Dataset already downloaded and verified.\")\n",
    "            return\n",
    "\n",
    "        root = self.root\n",
    "        print(\"Downloading dataset... (this might take a while)\")\n",
    "        download_url(self.url, root, self.filename, self.checksum)\n",
    "\n",
    "    def _extract(self):\n",
    "        path_to_zip = os.path.join(self.root, self.filename)\n",
    "        with zipfile.ZipFile(path_to_zip, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(self.root)\n",
    "\n",
    "    def _check_integrity(self):\n",
    "        path_to_zip = os.path.join(self.root, self.filename)\n",
    "        return check_integrity(path_to_zip, self.checksum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = DogsCatsDataset(\"../data/raw\", \"sample/train\", transform=train_trans)\n",
    "val_ds = DogsCatsDataset(\"../data/raw\", \"sample/valid\", transform=val_trans)\n",
    "\n",
    "batch_size = 2\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following if you want to use the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds = DogsCatsDataset(\"../data/raw\", \"train\", transform=train_trans)\n",
    "# val_ds = DogsCatsDataset(\"../data/raw\", \"calid\", transform=val_trans)\n",
    "# batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "Batch loading for datasets with multi-processing and different sample strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "val_dl = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model\n",
    "PyTorch offers quite a few [pre-trained networks](https://pytorch.org/docs/stable/torchvision/models.html) such as:\n",
    "- AlexNet\n",
    "- VGG\n",
    "- ResNet\n",
    "- SqueezeNet\n",
    "- DenseNet\n",
    "- Inception v3\n",
    "\n",
    "And there are more available via [pretrained-models.pytorch](https://github.com/Cadene/pretrained-models.pytorch):\n",
    "- NASNet,\n",
    "- ResNeXt,\n",
    "- InceptionV4,\n",
    "- InceptionResnetV2, \n",
    "- Xception, \n",
    "- DPN,\n",
    "- ...\n",
    "\n",
    "We'll use a simple resnet18 model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchsummary\n",
    "\n",
    "torchsummary.summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all parameters manually\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use our convenient functions from before\n",
    "freeze_all(model.parameters())\n",
    "assert all_frozen(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the last layer with a linear layer. New layers have `requires_grad = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(512, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not all_frozen(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(n_classes=2):\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    freeze_all(model.parameters())\n",
    "    model.fc = nn.Linear(512, n_classes)\n",
    "    model = model.to(DEVICE)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    get_trainable(model.parameters()),\n",
    "    lr=0.001,\n",
    "    # momentum=0.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 2\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(f\"Epoch {epoch+1}/{N_EPOCHS}\")\n",
    "    \n",
    "    # Train\n",
    "    model.train()  # IMPORTANT\n",
    "    \n",
    "    running_loss, correct = 0.0, 0\n",
    "    for X, y in train_dl:\n",
    "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_ = model(X)\n",
    "        loss = criterion(y_, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        print(f\"    batch loss: {loss.item():0.3f}\")\n",
    "        _, y_label_ = torch.max(y_, 1)\n",
    "        correct += (y_label_ == y).sum().item()\n",
    "        running_loss += loss.item() * X.shape[0]\n",
    "    \n",
    "    print(f\"  Train Loss: {running_loss / len(train_dl.dataset)}\")\n",
    "    print(f\"  Train Acc:  {correct / len(train_dl.dataset)}\")\n",
    "    \n",
    "    \n",
    "    # Eval\n",
    "    model.eval()  # IMPORTANT\n",
    "    \n",
    "    running_loss, correct = 0.0, 0\n",
    "    with torch.no_grad():  # IMPORTANT\n",
    "        for X, y in val_dl:\n",
    "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "                    \n",
    "            y_ = model(X)\n",
    "        \n",
    "            # Statistics\n",
    "            _, y_label_ = torch.max(y_, 1)\n",
    "            correct += (y_label_ == y).sum().item()\n",
    "            loss = criterion(y_, y)\n",
    "            running_loss += loss.item() * X.shape[0]\n",
    "    \n",
    "    print(f\"  Valid Loss: {running_loss / len(val_dl.dataset)}\")\n",
    "    print(f\"  Valid Acc:  {correct / len(val_dl.dataset)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "- Create your own module which takes any imagenet model (uses it unmodified as backbone) and adds a problem specific head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.module):\n",
    "    def __init__(self, backbone: nn.Module, n_classes: int):\n",
    "        super().__init__()\n",
    "        # self.backbone\n",
    "        # self.head = init_head(n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # TODO\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/the_real_reason.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foreword\n",
    "\n",
    "Material for this tutorial is here: https://github.com/sotte/pytorch_tutorial\n",
    "\n",
    "**Prerequisites:**\n",
    "- you have implemented machine learning models yourself\n",
    "- you know what deep learning is\n",
    "- you have used numpy\n",
    "- maybe you have used tensorflow or similar libs\n",
    "\n",
    "- if you use PyTorch on a daily basis, this tutorial is probably not for you\n",
    "\n",
    "**Goals:**\n",
    "- understand PyTorch concepts\n",
    "- be able to use transfer learning in PyTorch\n",
    "- be aware of some handy tools/libs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "You don't need a GPU to work on this tutorial, but everything is much faster if you have one.\n",
    "However, you can use Google's Colab with a GPU and work on this tutorial:\n",
    "[PyTorch + GPU in Google's Colab](0X_pytorch_in_googles_colab.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agenda\n",
    "\n",
    "See README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Overview\n",
    "\n",
    "\n",
    "> \"PyTorch - Tensors and Dynamic neural networks in Python\n",
    "with strong GPU acceleration.\n",
    "PyTorch is a deep learning framework for fast, flexible experimentation.\"\n",
    ">\n",
    "> -- https://pytorch.org/*\n",
    "\n",
    "This was the tagline prior to PyTorch 1.0.\n",
    "Now it's:\n",
    "\n",
    "> \"PyTorch - From Research To Production\n",
    "> \n",
    "> An open source deep learning platform that provides a seamless path from research prototyping to production deployment.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Build by run\" - what is that and why do I care?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/dynamic_graph.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a much better explanation of PyTorch (I think)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5449, -1.8257, -1.2288, -0.8771, -0.7182,  3.1249,  0.8576,  0.7684,\n",
       "          2.4977, -2.2945]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "def f(x):\n",
    "    res = x + x\n",
    "    # set_trace()  # <-- OMG! =D\n",
    "    return res\n",
    "\n",
    "x = torch.randn(1, 10)\n",
    "f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I like pytorch because\n",
    "- \"it's just stupid python\"\n",
    "- easy to debug\n",
    "- nice and extensible interface\n",
    "- research-y feel\n",
    "- research is often published as pytorch project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A word about TF\n",
    "TF 2 is about to be released.\n",
    "- eager by default\n",
    "- API cleanup\n",
    "- No more `session.run()`, `tf.control_dependencies()`, `tf.while_loop()`, `tf.cond()`, `tf.global_variables_initializer()`, etc.\n",
    "\n",
    "## TF and PyTorch\n",
    "- static vs dynamic\n",
    "- production vs prototyping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *\"The tyranny of choice\"*\n",
    "- TensorFlow\n",
    "- MXNet\n",
    "- Keras\n",
    "- CNTK\n",
    "- Chainer\n",
    "- caffe\n",
    "- caffe2\n",
    "- many many more\n",
    "\n",
    "All of them a good!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- Twitter: https://twitter.com/PyTorch\n",
    "- Forum: https://discuss.pytorch.org/\n",
    "- Tutorials: https://pytorch.org/tutorials/\n",
    "- Examples: https://github.com/pytorch/examples\n",
    "- API Reference: https://pytorch.org/docs/stable/index.html\n",
    "- Torchvision: https://pytorch.org/docs/stable/torchvision/index.html\n",
    "- PyTorch Text: https://github.com/pytorch/text\n",
    "- PyTorch Audio: https://github.com/pytorch/audio\n",
    "- AllenNLP: https://allennlp.org/\n",
    "- Object detection/segmentation: https://github.com/facebookresearch/maskrcnn-benchmark\n",
    "- Facebook AI Research Sequence-to-Sequence Toolkit written in PyTorch: https://github.com/pytorch/fairseq\n",
    "- FastAI http://www.fast.ai/\n",
    "- Stanford CS230 Deep Learning notes https://cs230-stanford.github.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Network\n",
    "Just to get an idea of how PyTorch feels like here are some examples of networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch                     # basic tensor functions\n",
    "import torch.nn as nn            # everything neural network\n",
    "import torch.nn.functional as F  # functional/stateless version of nn\n",
    "import torch.optim as optim      # optimizers :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple sequential model\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(20, 64, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (3): ReLU()\n",
       "  (4): AdaptiveAvgPool2d(output_size=1)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 64, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass\n",
    "model(torch.rand(16, 1, 32, 32)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu1): ReLU()\n",
       "  (conv2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu2): ReLU()\n",
       "  (aavgp): AdaptiveAvgPool2d(output_size=1)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple sequential model with named layers\n",
    "layers = OrderedDict([\n",
    "    (\"conv1\", nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5)),\n",
    "    (\"relu1\", nn.ReLU()),\n",
    "    (\"conv2\", nn.Conv2d(20,64,5)),\n",
    "    (\"relu2\", nn.ReLU()),\n",
    "    (\"aavgp\", nn.AdaptiveAvgPool2d(1)),\n",
    "])\n",
    "model = nn.Sequential(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(in_features=16 * 5 * 5, out_features=120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = F.adaptive_avg_pool2d(x, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Net()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.1a0+d94043a'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.17.3'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
